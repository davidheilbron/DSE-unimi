main = paste("Independence M-H Autocorr, when d = ", a_Independ))
title(main = paste("Independence M-H Autocorr, when d = ", a_Independ), line = 2, cex.main = 1.5)
par(las = 1, cex.lab = 1.5, cex.axis = 1.5, cex.main = 1.5)
grid()
fs <- 22
plot(output_RWNormal, type="l")
title(paste("Random walk M-H Chain, when d =", a_RWNormal))
par(font.size=fs)
par(las = 1, cex.lab = 1.5, cex.axis = 1.5, cex.main = 1.5)
autocorr.plot(output_RWNormal)
library(car)
autocorr.plot(output_RWNormal)
acf(output_RWNormal)
title(paste("Random walk M-H Autocorr, when d =", a_RWNormal))
plot(output_RWNormal, type="l")
title(paste("Random walk M-H Chain, when d =", a_RWNormal))
par(las = 1, cex.lab = 1.5, cex.axis = 1.5, cex.main = 1.5)
acf(output_RWNormal, title = (paste("Random walk M-H Autocorr, when d =", a_RWNormal)))
par(font.size=fs)
var(output_Independ)
# Metropolis-within-Gibbs sampling Hastings algorithm with RW normal proposal
# Closed form for lambda and not closed form for alpha
set.seed(100)
# Number of MH iterations
MHIter <- 40000
# You can try different values of the innovation
innov <- 0.8373 #sigma_alpha is the variance of the Normal RW proposal # best value = 0.9
n <- 50 # number of observations
# Information about the data
xbar <- 0.62 # sample mean based on the data --- mean(data)
sbar <- 0.4 # sample standard deviation based on the data --- sd(data)
xgbar <- 0.46 # sample geometric mean = sqrt(1/n) * prod(data)
# Prior elicitation/information
output <- matrix(0, nrow = MHIter, ncol = 2)
a <- 2; b <- 1 # are the hyperparameters of the Gamma prior for alpha ~ Ga(a,b)
c <- 3; d <- 1 # are the hyperparameters of the Gamma prior for gamma ~ Ga(c,d)
# Step 1 is set the counter = 1 and set the initial values of the chain
alpha <- (xbar/sbar)^2 # alpha^(0) = xbar^2/sbar^2
lambda <- xbar/(sbar)^2 # lambda^(0) = xbar/sbar^2
naccept <- 0 # initialize the counter of how many times I am accepting the proposed value
# MCMC algorithm
for (i in 1:MHIter) {
## Step 2 is the posterior distribution for lambda, which was in closed form
# lambda ~ Ga(c + n*alpha, d + n*xbar)
lambda <- rgamma(1, shape = c + n*alpha, rate = d + n*xbar) # Update of lambda
## Step 3 generate a proposed value for alpha* from a Normal RW
proposal <- rnorm(1, mean = alpha, sd = innov) # normal RW proposal
# Telling us to use only positive values of alpha since alpha is a
# positive scalar
if (proposal > 0) {
# Step 4 Evaluate the acceptance rate
accrate <- (proposal/alpha)^(a-1) * (gamma(alpha)/gamma(proposal))^n *
exp((b-n*log(lambda)-n*log(xgbar))*(alpha-proposal))
# Evaluate the logarithm transformation of the acceptance rate to
# solve numerical issues
logaprob <- (a - 1) * log(proposal/alpha) + n * log(gamma(alpha)/gamma(proposal)) +
(b + n * log(xgbar) + n * log(lambda)) * (proposal - alpha)
# Generate a random number from a uniform btw 0 and 1
u <- runif(1)
# Step 5 - Am I accepting the proposed value or not?
if (log(u) < logaprob) {
alpha <- proposal # accept the proposed value
naccept <- naccept + 1 # update the counter of the acceptance rate
}
output[i,1] <- alpha
output[i,2] <- lambda
}
## Graphical representation
cat("Acceptance rate = ", naccept/MHIter, "\n")
SigmaA <- 2.38 * sd(output[,1])
SigmaA
# Figure for alpha
plot(output[,1], type = "l", main = 'Chain for \alpha -- no burn-in')
# Figure for alpha
plot(output[,1], type = "l", main = "Chain for alpha -- no burn-in", xlab = "Iterations", ylab = "Alpha", cex.main = fs)
fs <- 22
# Figure for alpha
plot(output[,1], type = "l", main = "Chain for alpha -- no burn-in", xlab = "Iterations", ylab = "Alpha", cex.main = fs)
acf(output[,1], main = "Autocorrelation for alpha -- no burn-in", cex.main = fs)
# Figure for alpha
plot(output[,1], type = "l", main = "Chain for alpha -- no burn-in", xlab = "Iterations", ylab = "Alpha")
acf(output[,1], main = "Autocorrelation for alpha -- no burn-in", cex.main = fs)
# Figure for lambda
plot(output[,2], type = "l", main = "Chain for lambda -- no burn-in", xlab = "Iterations", ylab = "Lambda")
acf(output[,2], main = "Autocorrelation for lambda -- no burn-in", cex.main = fs)
# Figure for alpha with burn-in and thinning
thin <- 20
burnin <- 5001
plot(output[burnin:thin:nrow(output),1], type = "l", main = "Chain for alpha -- burn-in + thinning", xlab = "Iterations", ylab = "Alpha")
acf(output[burnin:thin:nrow(output),1], main = "Autocorrelation for alpha -- burn-in + thinning")
# Figure for lambda with burn-in and thinning
plot(output[burnin:thin:nrow(output),2], type = "l", main = "Chain for lambda -- burn-in + thinning", xlab = "Iterations", ylab = "Lambda")
acf(output[burnin:thin:nrow(output),2], main = "Autocorrelation for lambda -- burn-in + thinning")
# Lecture 17
library(mvtnorm)  # for the Gamma distribution function rgamma()
# Set the seed
set.seed(100)
# Number of MH iterations
MHIter <- 40000
# Number of MH iterations
MHIter <- 40000
# You can try different values of the hyperparameters for independence proposal
A <- 4; B <- 1/2
n <- 50 # number of observations
# Information about the data
xbar  <- 0.62 # sample mean based on the data --- mean(data)
sbar  <- 0.4  # sample standard deviation based on the data --- sd(data)
xgbar <- 0.46 # sample geometric mean = \sqrt{1/n}{\prod_{i=1}^n x_i} --- sqrt(1/n){prod(data)}
# Prior elicitation/information
output <- matrix(0, nrow = MHIter, ncol = 2)
a <- 2; b <- 1 # are the hyperparameters of the Gamma prior for alpha ~ Ga(a,b)
c <- 3; d <- 1 # are the hyperparameters of the Gamma prior for gamma ~ Ga(c,d)
# Step 1 is set the counter = 1 and set the initial values of the chain
alpha  <- (xbar/sbar)^2 # alpha^(0) = xbar^2/sbar^2
lambda <- xbar/(sbar)^2 # lambda^(0) = xbar/sbar^2
naccept <- 0 # initialize the counter of how many times I am accepting the proposed value
## MCMC algorithm
for (i in 1:MHIter) {
## Step 2 is the posterior distribution for lambda, which was in closed form
# lambda ~ Ga(c + n*alpha, d + n*xbar)
lambda   <- rgamma(n = 1, shape = c + n*alpha, rate = d + n*xbar) # Update of lambda
## Step 3 generate a proposed value for alpha* from a Normal RW
proposal <- rgamma(n = 1, shape = A, scale = 1/B) # normal RW proposal
# Telling us to use only positive values of alpha since alpha is a
# positive scalar
# Step 4 Evaluate the acceptance rate
accrate <- (proposal/alpha)^(a-1) *(gamma(alpha)/gamma(proposal))^n *
exp((b-n*log(lambda)-n*log(xgbar))*(alpha-proposal))
# Evaluate the logarithm transformation of the acceptance rate to
# solve numerical issues
logaprob <- (a - 1) * log(proposal/alpha) + n * log(gamma(alpha)/gamma(proposal)) +
(b + n * log(xgbar) + n * log(lambda)) * (proposal - alpha)
logaprob <- logaprob + dgamma(alpha, shape = A, scale = 1/B, log = TRUE) -
dgamma(proposal, shape = A, scale = 1/B, log = TRUE)
# Generate a random number from a uniform btw 0 and 1
u <- runif(n = 1, min = 0, max = 1)
# Step 5 - Am I accepting the proposed value or not?
if (log(u) < logaprob) {
alpha   <- proposal # accept the proposed value
naccept <- naccept + 1 # update the counter of the acceptance rate
}
output[i,1] <- alpha
output[i,2] <- lambda
}
# Graphical representation
cat(paste("Acceptance rate = ", naccept/MHIter, "\n"))
fs <- 22
# Figure for alpha
plot(output[,1], main="Chain for alpha -- no burn-in", xlab="Iteration", ylab="Alpha")
acf(output[,1], main="Autocorrelation for alpha -- no burn-in", lag.max=20, ylim=c(-0.2, 1))
par(mar=c(5, 4, 4, 2) + 0.1)
# Figure for lambda
plot(output[,2], main="Chain for lambda -- no burn-in", xlab="Iteration", ylab="Lambda")
acf(output[,2], main="Autocorrelation for lambda -- no burn-in", lag.max=20, ylim=c(-0.2, 1))
par(mar=c(5, 4, 4, 2) + 0.1)
# Figure for alpha with burn-in and thinning
thin <- 20
burnin <- 5001
plot(output[burnin:thin:nrow(output),1], main="Chain for alpha -- burn-in + thinning", xlab="Iteration", ylab="Alpha")
acf(output[burnin:thin:nrow(output),1], main="Autocorrelation for alpha -- burn-in + thinning", lag.max=20, ylim=c(-0.2, 1))
par(mar=c(5, 4, 4, 2) + 0.1)
# Figure for lambda with burn-in and thinning
plot(output[burnin:thin:nrow(output),2], main="Chain for lambda -- burn-in + thinning", xlab="Iteration", ylab="Lambda")
acf(output[burnin:thin:nrow(output),2], main="Autocorrelation for lambda -- burn-in + thinning", lag.max=20, ylim=c(-0.2, 1))
par(mar=c(5, 4, 4, 2) + 0.1)
library(tidyverse)
library(readxl)
library(lubridate)
library(zoo)
library(xts)
library(dplyr)
library(data.table)
library(imputeTS)
library(ggplot2)
library(tseries)
library(forecast)
library(bvartools)
install.packages("bvartools")
library(tidyverse)
library(readxl)
library(lubridate)
library(zoo)
library(xts)
library(dplyr)
library(data.table)
library(imputeTS)
library(ggplot2)
library(tseries)
library(forecast)
library(bvartools)
install.packages("coda")
library(coda)
library(bvartools)
data$Pigs_heads <- as.numeric(data$Pigs_heads)
data <- read_excel("data.xlsx", sheet = 'Data')
setwd("~/GitHub/Projects/Bayesian Statistics/Greenhouse gas emissions")
data <- read_excel("data.xlsx", sheet = 'Data')
data$Pigs_heads <- as.numeric(data$Pigs_heads)
data$Head_sheep <- as.numeric(data$Head_sheep)
data$Head_goat <- as.numeric(data$Head_goat)
data$Share_of_land_under_permanent_crops <- as.numeric(data$Share_of_land_under_permanent_crops)
data$Fertilizer_used_per_area_of_cropland <- as.numeric(data$Fertilizer_used_per_area_of_cropland)
data$Share_in_land_area_Forest_Land <- as.numeric(data$Share_in_land_area_Forest_Land)
str(data)
str(data$Rail_tracks_KM)
raw <- data
data$Rail_tracks_KM <- na_interpolation(data$Rail_tracks_KM, option = 'spline')
data %>% ggplot(aes(Year, Rail_tracks_KM)) + geom_line()
data %>% ggplot(aes(Year, Total_freight_loaded_and_unloaded)) + geom_line()
data$Total_freight_loaded_and_unloaded <- na_interpolation(data$Total_freight_loaded_and_unloaded, option = 'spline')
data %>% ggplot(aes(Year, Chicken_heads)) + geom_line()
data$Chicken_heads <- na_interpolation(data$Chicken_heads, option = 'spline')
data %>% ggplot(aes(Year, Chicken_heads)) + geom_line()
data %>% ggplot(aes(Year, Turkeys_heads)) + geom_line()
data$Turkeys_heads <- na_interpolation(data$Turkeys_heads, option = 'spline')
data %>% ggplot(aes(Year, Turkeys_heads)) + geom_line()
imp <- data
str(data)
summary(data)
data <- data %>%
mutate(res_capacity = hydro_capacity + geothermal_capacity +
wind_capacity + solar_capacity + biofuels_capacity +
biogas_capacity + waste_capacity) %>%
select(!c(hydro_capacity, geothermal_capacity,
wind_capacity, solar_capacity, biofuels_capacity,
biogas_capacity, waste_capacity))
str(data)
data <- data %>%
mutate(livestock_heads = Pigs_heads + Head_sheep + Head_goat +
Chicken_heads + Turkeys_heads + Cattle_heads + Buffalo_head) %>%
select(!c(Pigs_heads, Head_goat,Head_sheep, Chicken_heads,Turkeys_heads,Cattle_heads,Buffalo_head))
str(data)
plot(x = data$Year, y = data$livestock_heads, type = "l" )
plot(x = data$Year, y = data$res_capacity, type = "l")
final <- data
par(mfrow = c(1,1))
bayes <- data %>% select(net_greenhouse_pc, industrial_production, energy_imp_dep,
naturalgas_imports, total_energy_supply, gross_electricity_production)
head(bayes)
View(bayes)
bayes <- data %>% select(Year, net_greenhouse_pc, industrial_production, energy_imp_dep,
naturalgas_imports, total_energy_supply, gross_electricity_production)
gtsplot(bayes[,2:nrow(bayes)], dates = bayes[,1])
install.packages("Rcpp")
install.packages("ggplot2")
library(ggplot2)
devtools::install_github("kthohr/BMR")
gtsplot(bayes[,2:nrow(bayes)], dates = bayes[,1])
gtsplot(bayes[, 2:4], dates = bayes[, 1])
library(BMR)
install.packages("BMR")
install.packages("MTS")
library(MTS)
bayes_sca <- as.data.frame(apply(bayes, MARGIN = 2, scale)) #Apply second differences
View(bayes_sca)
plot(bayes_ts)
### BAYESIAN ATTEMPT #2
bvarx_data <- final %>% select(net_greenhouse_pc, industrial_production, naturalgas_imports)
### BAYESIAN ATTEMPT #2
y <- final %>% select(net_greenhouse_pc)
x <- final %>% select(industrial_production, naturalgas_imports)
rm(bvarx_data)
rm(bayes, bayes_sca)
varx <- VARX(zt = y, p = p, xt = x, m = m, include.mean = T, fixed = NULL, output = T)
p = 2 #VAR order - number of lags of the endogenous variables
m = 2 #number of lags of the exogenous variables
varx <- VARX(zt = y, p = p, xt = x, m = m, include.mean = T, fixed = NULL, output = T)
library(Matrix) # required for sparse matrices
# Set the seed
set.seed(100)
# Set the lag of the VAR
p <- 2  # if p > 4, need to change Y0 and Y below
# Gibbs sampler iterations
nsim   <- 20000
burnin <- 1000
setwd("C:/Users/Administrator/OneDrive/Studies/M.Sc. Data Science & Economics/2nd Year/Bayesian Analysis")
# Load data
Y_tmp <- read.csv('US_macrodata.csv')
View(Y_tmp)
Yraw  <- as.matrix(Y_tmp[,-1])
View(Yraw)
Dates <- Y_tmp[,1]
Y0 <- Yraw[1:4,] # save the first 4 obs as the initial conditions
Y  <- Yraw[5:nrow(Yraw),]
View(Y0)
T <- nrow(Y)
View(Y)
n <- ncol(Y)
y <- as.vector(t(Y))
# Prior hyperparameters
nu0 <- n + 3
S0 <- diag(n)
View(S0)
T <- nrow(Y) #number of observations
n <- ncol(Y) #number of features
y <- as.vector(t(Y)) #transform the features matrix into a single vector
k <- n*p + 1 # number of coefficients in each equation
n_hz  <- 20 # number of horizons for IRs
beta0 <- numeric(n*k)
# precision for coefficients = 1; for intercepts = 1/10
tmp <- rep(1,k*n)
tmp[seq(from = 1,to = k*n, by = k)] <- 1/10
tmp
iVbeta <- spDiags(tmp, 0, k*n, k*n)
iVbeta <- sparseMatrix(tmp, 0, k*n, k*n)
iVbeta <- diag(tmp, nrow = k*n, ncol = k*n)
View(iVbeta)
# Create the lagged variable
tmpY    <- rbind(Y0[(nrow(Y0)- p + 1):nrow(Y0),], Y)
View(tmpY)
X_tilde <- matrix(0, nrow(T), ncol(Y)*p)
X_tilde <- matrix(0, nrow = nrow(T), ncol = ncol(Y)*p)
X_tilde <- matrix(0, nrow = T, ncol = n*p)
View(X_tilde)
for (i in 1:p) {
X_tilde[,((i - 1)*n + 1):(i*n)] <- tmpY[(p - i + 1):(T - i + 1),]
}
X_tilde[,((i - 1)*n + 1):(i*n)] <- tmpY[(p - i + 1):(T - i),]
library(tidyverse)
library(readxl)
library(lubridate)
library(zoo)
library(xts)
library(dplyr)
library(data.table)
library(imputeTS)
library(ggplot2)
library(MTS)
library(BMR)
library(tidyverse)
library(readxl)
library(lubridate)
library(zoo)
library(xts)
library(dplyr)
library(data.table)
library(imputeTS)
library(ggplot2)
library(MTS)
library(tseries)
library(forecast)
library(bvartools)
library(coda)
setwd("~/GitHub/Projects/Bayesian Statistics/Greenhouse gas emissions")
data <- read_excel("data.xlsx", sheet = 'Data')
data$Pigs_heads <- as.numeric(data$Pigs_heads)
data$Head_sheep <- as.numeric(data$Head_sheep)
data$Head_goat <- as.numeric(data$Head_goat)
data$Share_of_land_under_permanent_crops <- as.numeric(data$Share_of_land_under_permanent_crops)
data$Fertilizer_used_per_area_of_cropland <- as.numeric(data$Fertilizer_used_per_area_of_cropland)
data$Share_in_land_area_Forest_Land <- as.numeric(data$Share_in_land_area_Forest_Land)
data$Rail_tracks_KM <- na_interpolation(data$Rail_tracks_KM, option = 'spline')
data %>% ggplot(aes(Year, Rail_tracks_KM)) + geom_line()
data %>% ggplot(aes(Year, Total_freight_loaded_and_unloaded)) + geom_line()
data$Total_freight_loaded_and_unloaded <- na_interpolation(data$Total_freight_loaded_and_unloaded, option = 'spline')
data %>% ggplot(aes(Year, Chicken_heads)) + geom_line()
data$Chicken_heads <- na_interpolation(data$Chicken_heads, option = 'spline')
data %>% ggplot(aes(Year, Chicken_heads)) + geom_line()
data %>% ggplot(aes(Year, Turkeys_heads)) + geom_line()
data$Turkeys_heads <- na_interpolation(data$Turkeys_heads, option = 'spline')
data %>% ggplot(aes(Year, Turkeys_heads)) + geom_line()
data <- data %>%
mutate(livestock_heads = Pigs_heads + Head_sheep + Head_goat +
Chicken_heads + Turkeys_heads + Cattle_heads + Buffalo_head) %>%
select(!c(Pigs_heads, Head_goat,Head_sheep, Chicken_heads,Turkeys_heads,Cattle_heads,Buffalo_head))
data <- data %>%
mutate(res_capacity = hydro_capacity + geothermal_capacity +
wind_capacity + solar_capacity + biofuels_capacity +
biogas_capacity + waste_capacity) %>%
select(!c(hydro_capacity, geothermal_capacity,
wind_capacity, solar_capacity, biofuels_capacity,
biogas_capacity, waste_capacity))
bayes <- data %>% select(Year, net_greenhouse_pc, industrial_production, energy_imp_dep,
naturalgas_imports, total_energy_supply, gross_electricity_production)
write.csv(bayes, file = "bayes_data.csv", row.names = FALSE)
bayes_data <- read_excel("bayes_data.xlsx", sheet = 'Data')
setwd("C:/Users/Administrator/Documents/GitHub/Projects/Bayesian Statistics/Greenhouse gas emissions")
bayes_data <- read_excel("bayes_data.xlsx", sheet = 'Data')
bayes_data <- read_excel("bayes_data.csv", sheet = 'Data')
bayes_data <- read.csv("bayes_data.csv", sheet = 'Data')
bayes_data <- read.csv("bayes_data.csv")
View(bayes_data)
Y_tmp <- bayes_data
Yraw  <- as.matrix(Y_tmp[,-1])
Dates <- Y_tmp[,1]
Y0 <- Yraw[1:4,] # save the first 4 obs as the initial conditions
Y  <- Yraw[5:nrow(Yraw),]
T <- nrow(Y) #number of observations
n <- ncol(Y) #number of features
View(Y)
View(Yraw)
Y0 <- Yraw[1:4,1] # save the first 4 obs as the initial conditions
Y  <- Yraw[5:nrow(Yraw),1]
T <- nrow(Y) #number of observations
n <- ncol(Y) #number of features
Y0 <- as.matrix(Yraw[1:4,1]) # save the first 4 obs as the initial conditions
Y  <- as.matrix(Yraw[5:nrow(Yraw),1])
T <- nrow(Y) #number of observations
n <- ncol(Y) #number of features
y <- as.vector(t(Y)) #transform the features matrix into a single vector
k <- n*p + 1 # number of coefficients in each equation
# Set the lag of the VAR
p <- 2
k <- n*p + 1 # number of coefficients in each equation
m <- 5 #number of exogenous features
k <- n*p + m*p + 1 # number of coefficients in each equation
n_hz  <- 5 # number of horizons for IRs
# Prior hyperparameters
nu0 <- 2*(m+n) #ask the professor
S0 <- diag(m+n)
View(S0)
beta0 <- numeric(n*k)
# precision for coefficients = 1; for intercepts = 1/10
tmp <- rep(1,k*n)
tmp[seq(from = 1,to = k*n, by = k)] <- 1/10
tmp
iVbeta <- diag(tmp, nrow = k*n, ncol = k*n)
View(iVbeta)
# Create the lagged variable
tmpY    <- rbind(Y0[(nrow(Y0) - p + 1):nrow(Y0),], Y)
nrow(Y0)
nrow(Y0) - p + 1
Y0[(nrow(Y0) - p + 1):nrow(Y0),]
Y
View(Y0)
try <- rbind(Y0[3:4,], Y)
try <- rbind(t(Y0[3:4,]), Y)
type(Y0)
class(Y0)
class(Y)
try <-Y0[(nrow(Y0) - p + 1):nrow(Y0),]
class(try)
try <-as.matrix(Y0[(nrow(Y0) - p + 1):nrow(Y0),])
class(try)
View(try)
rbind(try, Y)
# Create the lagged variable
tmpY    <- rbind(as.matrix(Y0[(nrow(Y0) - p + 1):nrow(Y0),]), Y)
rm(try)
X_tilde <- matrix(0, nrow = T, ncol = (n + m)*p)
View(X_tilde)
for (i in 1:p) {
X_tilde[,((i - 1)*n + 1):(i*n)] <- tmpY[(p - i + 1):(T - i),]
} #not working, must fix it
View(Y_tmp)
View(tmpY)
for (i in 1:p) {
X_tilde[,((i - 1)*n + 1):(i*n)] <- as.matrix(tmpY[(p - i + 1):(T - i),])
} #not working, must fix it
as.matrix(X_tilde[,((i - 1)*n + 1):(i*n)]) <- as.matrix(tmpY[(p - i + 1):(T - i),])
i = 1
X_tilde[,((i - 1)*n + 1):(i*n)]
View(X_tilde)
tmpY[(p - i + 1):(T - i),]
dim(X_tilde[,((i - 1)*n + 1):(i*n)])
dim(as.matrix(X_tilde[,((i - 1)*n + 1):(i*n)]))
dim(as.matrix(tmpY[(p - i + 1):(T - i),]))
dim(as.matrix(tmpY[2:26]))
lag_1 <- shift(Yraw, 1)
lag_1 <- shift(Yraw[,1], 1)
lag_1 <- na.omit(lag_1)
lag_2 <- shift(Yraw[,1], 2)
lag_2 <- na.omit(lag_2)
lag_1 <- lag_1[4:nrow(lag_1),]
nrow(lag_1)
lag_1 <- lag_1[4:length(lag_1),]
lag_1 <- as.matrix(lag_1[4:nrow(lag_1),])
class(lag_1)
lag_1 <- as.vector(lag_1[4:nrow(lag_1),])
lag_1 <- as.vector(lag_1)
class(lag_1)
lag_1 <- lag_1[4:nrow(lag_1),]
lag_1 <- as.matrix(lag_1)
lag_1 <- lag_1[4:nrow(lag_1),]
lag_2 <- as.matrix(lag_2)
lag_2 <- lag_2[4:nrow(lag_2),]
lag_2 <- shift(Yraw[,1], 2)
lag_2 <- na.omit(lag_2)
lag_2 <- as.matrix(lag_2)
lag_2 <- lag_2[3:nrow(lag_2),]
View(Yraw)
lag_1 <- shift(Yraw, 1)
mlag_1 <- rbind(NA, Yraw[,-1],)
mlag_1 <- rbind(NA, Yraw[,-1])
View(mlag_1)
mlag_1 <- rbind(NA, Yraw[-1,])
class(mlag_1)
mlag_1 <- na.omit(mlag_1)
mlag_1 <- mlag_1[4:nrow(mlag_1),]
dim(mlag1)
dim(mlag_1)
Yraw[-c(1,2)]
mlag_2 <- rbind(NA, Yraw[-c(1,2)],)
mlag_2 <- rbind(NA, Yraw[-c(1,2),])
mlag_2 <- na.omit(mlag_2)
mlag_2 <- mlag_2[3:nrow(mlag_2),]
View(mlag_1)
View(mlag_2)
mlag_1 <- Yraw[4:nrow(Yraw)-1,]
for (i in 1:p) {
View(X_tilde)
dim(mlag_1)
for (i in 1:p) {
for (i in 1:p){
X_tilde[,((i - 1)*(n+m) + 1):(i*(n+m))] <- tmpY[(p - i + 1):(T - i),]
}
View(X_tilde)
for (i in 1:p){
X_tilde[,((i - 1)*(n+m) + 1):(i*(n+m))] <- tmpY[(p - i + 1):(T - i),]
}
mlag_1 <- Yraw[4:nrow(Yraw)-1,]
View(mlag_1)
